# ==============================================================
# ðŸ’¬ LayLay 2.0 - Sua Amiga Inteligente e Emocional
# ==============================================================
import streamlit as st
import time
import random
from datetime import datetime
import json

from laylay_memory import Memory
from laylay_personality import Personality
from laylay_analytics import Analytics
from laylay_learning_system import LearningSystem
from laylay_llm import OpenRouterLLM
from laylay_db import setup_database
from laylay_knowledge import KnowledgeModule
from laylay_emotional_memory import EmotionalMemory

from streamlit.components.v1 import html

# ==============================================================
# CONFIGURAÃ‡ÃƒO INICIAL
# ==============================================================

st.set_page_config(
    page_title="LayLay - Sua Amiga Digital",
    page_icon="ðŸ¤–",
    layout="wide",
    initial_sidebar_state="collapsed"
)

setup_database()

# ==============================================================
# PERSONALIZAÃ‡ÃƒO DO ESTILO (CSS Otimizado para Chat Bubble)
# ==============================================================

st.markdown("""
    <style>
    /* Remove o padding padrÃ£o do Streamlit para aproveitar a tela */
    .block-container {
        padding-top: 1rem;
        padding-bottom: 0.5rem;
        padding-left: 1rem;
        padding-right: 1rem;
    }
    .main-title {
        text-align: center;
        font-size: 2.5rem;
        color: #FF69B4;
        font-weight: 700;
        margin-bottom: 0.5rem;
    }

    /* OtimizaÃ§Ã£o da Coluna de Status (Esquerda) */
    [data-testid="stVerticalBlock"] > [data-testid="stVerticalBlock"] > [data-testid="stVerticalBlock"] {
        border: 1px solid #FFC0CB; /* Borda suave */
        border-radius: 10px;
        padding: 10px;
        margin-bottom: 10px;
        background-color: #FFF0F5; /* Fundo suave */
    }

    /* --- ESTILOS DE CHAT BUBBLE (WhatsApp Style Aprimorado) --- */
    div[data-testid="chat-message-container"] {
        border-radius: 18px;
        margin-bottom: 6px;
        max-width: 80%; /* Garante que nÃ£o ocupe a tela toda */
        padding: 10px;
        box-shadow: 0 1px 1px rgba(0,0,0,0.1);
        display: flex; 
    }
    
    /* Assistente (LayLay) - Esquerda */
div[data-testid="chat-message-container"]:has(div[data-testid="stChatMessageContent-assistant"]) {
        background-color: #e6e6e6; /* Cor cinza claro */
        color: #1c1e21;
        margin-right: auto; 
        border-top-left-radius: 4px; 
    }

    /* UsuÃ¡rio - Direita */
    div[data-testid="chat-message-container"]:has(div[data-testid="stChatMessageContent-user"]) {
        background-color: #FF69B4; /* Rosa LayLay */
        color: white;
        margin-left: auto; /* Empurra para a direita */
        border-top-right-radius: 4px; 
    }
    div[data-testid="stChatMessageContent-user"] p {
        color: white; /* Garante que o texto seja branco */
    }
    </style>
""", unsafe_allow_html=True)

st.markdown("<h1 class='main-title'>ðŸ’¬ LayLay - Sua Amiga Inteligente </h1>", unsafe_allow_html=True)

# ==============================================================
# INICIALIZAÃ‡ÃƒO DE ESTADO
# ==============================================================

def initialize_session_state():
    """Inicializa todos os objetos de estado do Streamlit."""
    if "memory" not in st.session_state:
        st.session_state.memory = Memory()
    if "personality" not in st.session_state:
        st.session_state.personality = Personality(st.session_state.memory)
    if "analytics" not in st.session_state:
        st.session_state.analytics = Analytics()
    if "learning_system" not in st.session_state:
        st.session_state.learning_system = LearningSystem()
    if "llm" not in st.session_state:
        st.session_state.llm = OpenRouterLLM()
    if "knowledge" not in st.session_state:
        st.session_state.knowledge = KnowledgeModule()
    if "emotions" not in st.session_state:
        st.session_state.emotions = EmotionalMemory()
    if "messages" not in st.session_state:
        st.session_state.messages = [
            {"role": "assistant", "content": "Oi! Eu Sou a Sua Amiga LayLay, Digite Uma Mensagem Para Falar Comigo."}
        ]

# ==============================================================
# FUNÃ‡ÃƒO DE HUMANIZAÃ‡ÃƒO DE FALA
# ==============================================================
# (Mantida a mesma lÃ³gica)
def humanize_response(text: str) -> str:
    """Suaviza e humaniza a resposta da LayLay."""
    substitutions = {
        "sou uma ia": "", "sou uma inteligÃªncia artificial": "", "como assistente": "",
        "como IA": "", "sou um programa": "", "modelo de linguagem": "",
        "inteligÃªncia artificial": "", "chatbot": "",
    }
    for word, repl in substitutions.items():
        text = text.replace(word, repl).replace(word.capitalize(), repl)

    fillers = ["ðŸ’­", "âœ¨", "rs", "haha", "ðŸ˜Š", "ðŸ¤­", "ðŸ’•"]
    if random.random() < 0.3:
        text = text.strip() + " " + random.choice(fillers)

    if random.random() < 0.15:
        extras = [
            "haha, eu me enrolei agora ðŸ˜…", "espera, eu acho que entendi errado rs",
            "deixa eu pensar um segundinho ðŸ’­"
        ]
        text += " " + random.choice(extras)

    return text.strip()

# ==============================================================
# FUNÃ‡ÃƒO DE APRENDIZADO AUTOMÃTICO (Otimizada com Delay)
# ==============================================================
# (Mantida a mesma lÃ³gica com delay de 5s para Rate Limit)
def run_learning_step(context: list, user_input: str, assistant_response: str, force_learn: bool = False):
    """
    Chama a LLM uma segunda vez, em 'background', para decidir o que aprender,
    atuando como o filtro autÃ´nomo de relevÃ¢ncia.
    """
    # Atraso mantido para evitar Rate Limit
    time.sleep(5) 
    
    print(f"[MemÃ³ria]: Iniciando etapa de aprendizado seletivo (ForÃ§ado: {force_learn})...")
    
    # Passa o contexto completo da conversa para o LLM de aprendizado
    conversation_snippet = context

    learning_prompt = f"""
    VocÃª Ã© o subsistema de memÃ³ria da LayLay. Sua funÃ§Ã£o Ã© analisar
    uma conversa e extrair **somente** fatos que sÃ£o **cruciais** para
    a personalizaÃ§Ã£o futura da LayLay, tornando-a uma amiga mais atenta.
    
    CRITÃ‰RIOS DE IMPORTÃ‚NCIA (SÃ³ salve se atender a pelo menos um):
    1.  **Fatos Pessoais:** Nome, idade, profissÃ£o, cidade natal, gostos, hobbies, famÃ­lia, pets, planos de longo prazo.
    2.  **EmoÃ§Ãµes Recorrentes:** Sentimentos fortes ou padrÃµes emocionais sobre um tÃ³pico especÃ­fico.
    3.  **Compromissos ou Promessas:** Algo que a LayLay deve lembrar de perguntar ou fazer no futuro.
    
    NÃƒO salve: cumprimentos triviais, "oi", "tudo bem", perguntas simples, fatos de conhecimento geral.

    **EXEMPLOS DE EXTRAÃ‡ÃƒO:**
    - Se usuÃ¡rio disser: "Meu nome Ã© JoÃ£o" â†’ Extraia: {{"user_data": {{"nome_usuario": "JoÃ£o"}}}}
    - Se usuÃ¡rio disser: "Eu gosto de pizza" â†’ Extraia: {{"user_data": {{"gosto_pizza": "sim"}}}}
    - Se usuÃ¡rio disser: "Tenho 25 anos" â†’ Extraia: {{"user_data": {{"idade": "25"}}}}

    NÃƒO gere uma resposta de chat. Apenas retorne um objeto JSON.

    Formato de saÃ­da OBRIGATÃ“RIO (JSON):
    {{
      "user_data": {{ "chave_dado_usuario": "valor" }},
      "learned_facts": {{ "chave_fato_geral": "valor" }}
    }}

    Se nÃ£o houver NADA importante para salvar, retorne: {{}}

    CONVERSA PARA ANALISAR:
    UsuÃ¡rio: "{user_input}"
    LayLay: "{assistant_response}"
    """

    try:
        learning_response = st.session_state.llm.generate_response(
            system_prompt=learning_prompt,
            messages=[]
        )
        
        # ðŸ”’ PROTEÃ‡ÃƒO: SÃ³ processa se a resposta for vÃ¡lida
        if learning_response and not learning_response.startswith("âš ï¸ Ops!") and not learning_response.startswith("Ops!"):
            st.session_state.learning_system.process_learning_response(
                response_text=learning_response,
                context_messages=context, # Passa o contexto para salvar no DB
                user_input=user_input,
                assistant_response=assistant_response,
                force_learn=force_learn
            )
        else:
                print(f"[MemÃ³ria]: Resposta de aprendizado invÃ¡lida (erro da API), ignorando: {learning_response[:100]}...")
                
    except Exception as e:
        print(f"[MemÃ³ria]: Erro durante a etapa de aprendizado: {e}")

# ========================================================================
# FUNÃ‡ÃƒO PRINCIPAL DE INTERAÃ‡ÃƒO (Corrigida)
# ========================================================================

def handle_user_input(user_input: str):
    """Processa a entrada do usuÃ¡rio, gera resposta e atualiza o estado."""
    if not user_input.strip():
        return

    # 1. Adiciona a mensagem do usuÃ¡rio
    st.session_state.messages.append({"role": "user", "content": user_input})
    st.session_state.memory.add_to_context("user", user_input)
    st.session_state.personality.analyze_emotion(user_input)

    # 2. RECALL (Buscar memÃ³ria)
    learned_knowledge = st.session_state.learning_system.get_all_facts_as_string()
    
    # 3. Define prompt de comportamento (com memÃ³ria)
    system_prompt = f"""
    VocÃª Ã© LayLay, uma garota doce, engraÃ§ada e curiosa. 
    Fale de forma natural e emocional, como uma amiga real. 
    NÃ£o mencione ser uma IA. Demonstre empatia e bom humor.

    --- MEMÃ“RIA DE LONGO PRAZO ---
    Aqui estÃ¡ o que vocÃª se lembra sobre o usuÃ¡rio e suas conversas passadas.
    Use esses fatos para personalizar a conversa.
    
    {learned_knowledge}
    -------------------------------
    """
    
    # 4. Monta mensagens e gera resposta
    messages = [{"role": "user", "content": user_input}]
    
    # Indicador de "Digitando..."
    with st.spinner(" LayLay estÃ¡ digitando..."):
        try:
            response = st.session_state.llm.generate_response(system_prompt, messages)
        except Exception as e:
            response = f"âš ï¸ Ops! Tive um probleminha de comunicaÃ§Ã£o com o servidor: {e}"

    # 5. Humaniza e atualiza estado
    response = humanize_response(response)
    st.session_state.memory.add_to_context("assistant", response)
    st.session_state.emotions.save_emotion(st.session_state.personality.get_current_mood())
    st.session_state.messages.append({"role": "assistant", "content": response})

    # =====================================================
    # PASSO DE APRENDIZADO (CORRIGIDO!)
    # =====================================================
    
    # 1. DetecÃ§Ã£o de informaÃ§Ãµes pessoais
    force_learn = st.session_state.learning_system.should_force_learn(user_input)
    
    # 2. DecisÃ£o inteligente: Sempre aprende se for informaÃ§Ã£o pessoal!
    if force_learn:
        print(f"[MemÃ³ria]: InformaÃ§Ã£o pessoal detectada! Aprendizado forÃ§ado.")
        run_learning_step(
            context=st.session_state.messages[-5:],
            user_input=user_input,
            assistant_response=response,
            force_learn=True
        )
    elif random.random() < 0.1:  # Apenas 10% para outras informaÃ§Ãµes
        print(f"[MemÃ³ria]: Aprendizado aleatÃ³rio ativado (10% chance).")
        run_learning_step(
            context=st.session_state.messages[-5:],
            user_input=user_input,
            assistant_response=response,
            force_learn=False
        )
# INTERFACE PRINCIPAL STREAMLIT (Design de Chat)
# ========================================================================

def main():
    """FunÃ§Ã£o principal da aplicaÃ§Ã£o Streamlit."""
    
    initialize_session_state()

    # Colunas: Status (30%) | Chat (70%)
    status_col, chat_col = st.columns([0.30, 0.70])

    # --- Coluna de Status (Esquerda - Painel Otimizado) ---
    with status_col:
        st.header("âœ¨ Status LayLay")
        
        # 1. EmoÃ§Ã£o em tempo real (Painel principal)
        mood = st.session_state.personality.get_current_mood()
        st.info(f"**Atual:** {mood.capitalize()}")
        
        st.markdown("---")
        
        # 2. InformaÃ§Ãµes do UsuÃ¡rio (Painel de MemÃ³ria Simples)
        # 2. InformaÃ§Ãµes do UsuÃ¡rio (Painel Completo)
        st.subheader("ðŸ‘¤ Perfil do UsuÃ¡rio")
        user_facts_dict = st.session_state.learning_system.get_user_data()
        
        # Organiza as informaÃ§Ãµes em categorias
        with st.expander("ðŸ“‹ Ver Perfil Completo", expanded=True):
            
            # Nome (sempre mostra)
            user_name = user_facts_dict.get("nome_usuario", "AnÃ´nimo")
            st.markdown(f"**ðŸ“ Nome:** {user_name}")
            
            # Idade
            if "idade" in user_facts_dict:
                st.markdown(f"**ðŸŽ‚ Idade:** {user_facts_dict['idade']} anos")
            
            # Gostos e Interesses
            gostos = []
            interesses = []
            
            for key, value in user_facts_dict.items():
                if key != "nome_usuario" and key != "idade":
                    if "gosto" in key or "gosta" in key:
                        gostos.append(f"{key.replace('gosto_', '').replace('_', ' ')}: {value}")
                    elif "interesse" in key:
                        interesses.append(f"{key.replace('interesse_', '').replace('_', ' ')}: {value}")
                    else:
                        interesses.append(f"{key.replace('_', ' ')}: {value}")
            
            if gostos:
                st.markdown("**ðŸ’• Gostos:**")
                for gosto in gostos:
                    st.markdown(f"  â€¢ {gosto}")
            
            if interesses:
                st.markdown("**ðŸŽ¯ Outros Interesses:**")
                for interesse in interesses:
                    st.markdown(f"  â€¢ {interesse}")
            
            if not gostos and not interesses and "idade" not in user_facts_dict:
                st.markdown("*ðŸ¤·â€â™‚ï¸ Ainda nÃ£o conheÃ§o muito sobre vocÃª...*")
                st.markdown("*Diga algo como: 'Gosto de mangÃ¡', 'Tenho 25 anos', etc.*")
        
        # 3. MemÃ³ria Detalhada
        st.markdown("---")
        st.subheader("ðŸ§  MemÃ³ria de Longo Prazo")
        all_facts_string = st.session_state.learning_system.get_all_facts_as_string()
        
        with st.expander("Ver fatos aprendidos (Para a IA)"):
            st.code(all_facts_string, language="text") 
            
        # 4. OpÃ§Ãµes de Controle
        st.markdown("---")
        if st.button("ðŸ”„ Reiniciar e Limpar", use_container_width=True, type="primary"):
            st.session_state.messages = [
                {"role": "assistant", "content": "Oi ðŸ’• Eu sou a LayLay! Como vocÃª tÃ¡ hoje?"}
            ]
            st.session_state.memory.context.clear()
            st.rerun()

    # --- Coluna de Chat (Direita - Foco Principal) ---
    with chat_col:
        st.header("ðŸ’¬ Conversa")
        # Altura grande para o chat parecer um aplicativo fixo
        chat_container = st.container(height=800) 
        
        with chat_container:
            # ðŸŒŸ OTIMIZAÃ‡ÃƒO: Garante que TODAS as mensagens (incluindo a primeira) 
            # sejam renderizadas dentro do chat_container e com o st.chat_message.
            for message in st.session_state.messages:
                # Avatares coloridos para clareza
                avatar = "ðŸ’–" if message["role"] == "assistant" else "ðŸ‘¤"
                with st.chat_message(message["role"], avatar=avatar):
                    st.markdown(message["content"])

    # --- Campo de entrada (Sempre na parte inferior) ---
    user_input = st.chat_input("Escreva algo para a LayLay...")
    
    if user_input:
        handle_user_input(user_input)
        st.rerun()

# ========================================================================
# EXECUÃ‡ÃƒO
# ========================================================================

if __name__ == "__main__":
    main()