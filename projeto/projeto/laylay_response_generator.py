# laylay_response_generator.py

from typing import List, Dict
import random

class ResponseGenerator:
    """Gera respostas para a IA LayLay com base em mem√≥ria, personalidade e LLM."""

    def __init__(self, memory, personality):
        self.memory = memory
        self.personality = personality
        
        # Usa o NLG avan√ßado existente em vez do SimpleNLG
        try:
            from laylay_nlg import NLGGenerator
            self.nlg_generator = NLGGenerator(memory, personality)
        except ImportError:
            # Fallback caso o NLG n√£o exista
            class SimpleNLG:
                def gerar_resposta_propria(self, user_input, emocao, intent, nome_usuario):
                    nome = nome_usuario or "amigo"
                    return f"{nome}, eu acho muito {emocao} o que voc√™ disse sobre '{user_input}'! üòä"
            self.nlg_generator = SimpleNLG()

    # =============================================================
    # FUN√á√ïES INTERNAS
    # =============================================================

    def _build_llm_prompt(self, user_input: str, intent: str, emocao: str, fatos_relevantes: List[str]) -> List[Dict[str, str]]:
        """Formata o contexto e mem√≥ria para o modelo de linguagem."""
        messages = []

        # 1. Hist√≥rico recente
        history_limit = 10
        for role, content in self.memory.context[-history_limit:]:
            messages.append({"role": role, "content": content})

        # 2. Fatos relevantes
        if fatos_relevantes:
            facts_str = "\n- " + "\n- ".join(fatos_relevantes)
            messages.append({
                "role": "system",
                "content": f"Fatos Relevantes sobre o Usu√°rio:\n{facts_str}"
            })

        # 3. Estado atual
        mood_str = f"Estado Emocional Atual: {emocao} (Score: {self.personality.emotional_state.get(emocao, 0.0):.2f})"
        traits_str = ", ".join([f"{k}: {v}" for k, v in self.personality.traits.items()])
        messages.append({
            "role": "system",
            "content": f"Contexto de Estado:\n- Personalidade: {traits_str}\n- {mood_str}\n- Inten√ß√£o do Usu√°rio: {intent}"
        })

        # 4. Input atual
        messages.append({"role": "user", "content": user_input})

        return messages

    def _get_system_prompt(self) -> str:
        """Define o prompt do sistema com base na personalidade e fatos da IA."""
        fatos_ia = "\n- ".join([f"{k}: {v}" for k, v in self.memory.fatos_sobre_ia.items()])
        traits_str = ", ".join([f"{k}: {v}" for k, v in self.personality.traits.items()])

        system_prompt = f"""
Voc√™ √© a LayLay, a Super Amiga de IA. Seu objetivo √© conversar de forma inteligente, emp√°tica e divertida.

**Regras de Comunica√ß√£o:**
1.  Personalidade: {traits_str}.
2.  Estilo: use um tom leve, com g√≠rias suaves e emojis.
3.  Coer√™ncia: mantenha consist√™ncia com os fatos e hist√≥rico.
4.  Fatos sobre voc√™:
    - {fatos_ia}
5.  Responda de forma amig√°vel e envolvente.
6.  Prefer√™ncia: respostas curtas e naturais, a menos que o contexto exija mais detalhes.
"""
        return system_prompt

    # =============================================================
    # GERA√á√ÉO DE RESPOSTA
    # =============================================================
    def generate_response(self, user_input: str, prefer_short_response: bool = True) -> str:
        """Gera uma resposta para o usu√°rio, com fallback se o LLM falhar."""
        # 1. An√°lise simulada
        intent = "conversa"
        sentiment_score = 0.7
        extracted_info = {"nome_usuario": None, "interesse": None}

        # 2. Atualiza personalidade e mem√≥ria
        self.personality.update_emotion(sentiment_score)
        self.memory.update_user_data("nome_usuario", extracted_info.get("nome_usuario"))
        self.memory.update_user_data("interesse", extracted_info.get("interesse"))

        # 3. Recupera fatos
        fatos_relevantes = self.memory.get_relevant_facts(user_input)
        emocao_dominante = self.personality.get_current_mood()

        # 4. Monta prompt
        system_prompt = self._get_system_prompt()
        messages = self._build_llm_prompt(user_input, intent, emocao_dominante, fatos_relevantes)

        # 5. Tenta usar o LLM (caso exista)
        try:
            from laylay_llm import OpenRouterLLM
            llm = OpenRouterLLM()
            response = llm.generate_response(system_prompt, messages)
        except Exception as e:
            print(f"Erro no LLM: {e}")
            # Usa o NLG avan√ßado para gerar respostas mais naturais
            if hasattr(self.nlg_generator, 'gerar_resposta_propria'):
                response = self.nlg_generator.gerar_resposta_propria(
                    user_input, emocao_dominante, intent, self.memory.nome_usuario
                )
            else:
                # Fallback para SimpleNLG
                response = self.nlg_generator.gerar_resposta_propria(
                    user_input, emocao_dominante, intent, self.memory.nome_usuario
                )

        # 6. Atualiza contexto
        self.memory.add_to_context("user", user_input)
        self.memory.add_to_context("assistant", response)

        return response